# About me
I am a Computer Science Engineer from India.  
I'm passionate about computers and software especially the architecture design dealing with interplay of the various subsystems. Thus game engines fascinate me as they involve several interconnected modules that need to work together efficiently in order to provide realtime performance.  
I'm also enthusiastic about research in Artificial Intelligence especially Natural Language Processing, Reinforcement Learning, and Causal Intelligence. The applicaitons of AI in general reasoning and sentient systems is fascinating and I dabble.

# Projects
(The webpage is under reconstruction, so some information may be missing or out of date)
## [Apex Game Engine](/ApexGameEngine) [<img src="assets/GitHub-Mark/PNG/GitHub-Mark-32px.png" alt="GitHub repo" width="20px">](https://github.com/xdevapps/ApexGameEngine)
* My pet project, under which I am learning to develop my own C++ OpenGL game engine. Inspired by [The Game Engine series](https://youtube.com/playlist?list=PLlrATfBNZ98dC-V-N3m0Go4deliWHPFwT), [LearnOpenGL](https://learnopengl.com/) and [Game Engine Architecture book](https://www.gameenginebook.com/).

<video width="800" height="450" controls>
  <source src="https://user-images.githubusercontent.com/45060273/194432860-0ba5dbe1-848b-4014-9f10-dd253f9fcbd5.mp4" type="video/mp4">
  Download <a href="https://user-images.githubusercontent.com/45060273/194432860-0ba5dbe1-848b-4014-9f10-dd253f9fcbd5.mp4">mp4</a>
</video>

<video width="800" height="450" controls>
  <source src="https://github.com/athanggupte/xdevapps.github.io/assets/45060273/83837f07-03d1-412c-8976-3befd338d90c" type="video/mp4">
  Download <a href="https://github.com/athanggupte/xdevapps.github.io/assets/45060273/83837f07-03d1-412c-8976-3befd338d90c">mp4</a>
</video>

#### Update 01/10/2023 - Added Bloom effect

![bloom-demo](https://user-images.githubusercontent.com/45060273/211588060-1490bed0-105d-4d5b-b7a9-e2e9a98a555f.png)

## [Un-Real](https://athang213.itch.io/un-real)
* 2D side-scroller adventure puzzle game made for the [Brackeys GameJam 2022.1](https://itch.io/jam/brackeys-7/rate/1420119).

<iframe frameborder="0" src="https://itch.io/embed/1420119" width="552" height="167"><a href="https://athang213.itch.io/un-real">Un-Real by athang213, shockwave20599</a></iframe>


## [Neurons](/Neurons) [<img src="assets/GitHub-Mark/PNG/GitHub-Mark-32px.png" alt="GitHub repo" width="20px">](https://github.com/xdevapps/Neurons)
* A browser-based GUI neural network editor for designing neural network architectures with Keras backend.

## [ApexIK](/ApexIK) [<img src="assets/GitHub-Mark/PNG/GitHub-Mark-32px.png" alt="GitHub repo" width="20px">](https://github.com/xdevapps/ApexIK)
* a FABRIK (Forward And Backward Reaching IK) Inverse Kinematics library for procedural animation.

# Publications
### [Knowledge Graph Generation From Text Using Neural Machine Translation Techniques](https://ieeexplore.ieee.org/document/9510164/)
<details> <summary>Abstract</summary>
  As the applications of data science become pervasive in daily life, there arises a dire need to represent data in machine-understandable forms like knowledge graphs. Over the years, there have been numerous developments in extracting entities and their relations for augmenting knowledge graphs, but many of them depend on external dependencies like dependency parsers and part-of-speech taggers. These approaches, while indeed accomplishing this task, induce a certain degree of inflexibility in their implementation. Recent explorations in this domain have attempted to utilize Neural Machine Translation techniques to convert natural language to SPARQL queries, with a focus on information retrieval from pre-established Knowledge Graphs. We explore in detail, the variety of approaches followed for SPARQL machine translation, with a keen focus on insertion of extracted knowledge into the graphs.As part of our research, we curated a dataset- Scientists-100, extracted from Dbpedia, for the task of translation of natural language to SPARQL insertion statements. We also propose two models â€“ an Attention RNN and a Transformer for the same. These models achieve an accuracy of 99.27% and a 98.61% respectively on the dataset. In addition to this, we present a metric for examining the syntactic accuracy of the generated SPARQL statements. Our models exhibit 99.25% and 98.71% syntactic accuracy as calculated on the same.
</details>

# Apart from tech
MusicðŸŽ¶ GuitarðŸŽ¸ TennisðŸŽ¾

